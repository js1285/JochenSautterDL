{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "start training autoencoder with learning rate 0.01\n",
      "step 0, train loss (one batch a 64) 0.09465962648391724\n",
      "step 0, validation loss (one val.batch a 64) 0.10332701355218887\n",
      "step 100, train loss (one batch a 64) 0.029472408816218376\n",
      "step 100, validation loss (one val.batch a 64) 0.028037110343575478\n",
      "step 200, train loss (one batch a 64) 0.023142630234360695\n",
      "step 200, validation loss (one val.batch a 64) 0.022068558260798454\n",
      "step 300, train loss (one batch a 64) 0.020953146740794182\n",
      "step 300, validation loss (one val.batch a 64) 0.019706349819898605\n",
      "step 400, train loss (one batch a 64) 0.021812230348587036\n",
      "step 400, validation loss (one val.batch a 64) 0.019397979602217674\n",
      "step 500, train loss (one batch a 64) 0.020863905549049377\n",
      "step 500, validation loss (one val.batch a 64) 0.02075536921620369\n",
      "step 600, train loss (one batch a 64) 0.02206004224717617\n",
      "step 600, validation loss (one val.batch a 64) 0.02138213999569416\n",
      "step 700, train loss (one batch a 64) 0.02199135720729828\n",
      "step 700, validation loss (one val.batch a 64) 0.020915547385811806\n",
      "step 800, train loss (one batch a 64) 0.02073366753757\n",
      "step 800, validation loss (one val.batch a 64) 0.01861419714987278\n",
      "step 900, train loss (one batch a 64) 0.017536671832203865\n",
      "step 900, validation loss (one val.batch a 64) 0.021504027768969536\n",
      "step 1000, train loss (one batch a 64) 0.019345419481396675\n",
      "step 1000, validation loss (one val.batch a 64) 0.01863122172653675\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#\n",
    "#\n",
    "# A CONVOLUTIONAL AUTOENCODER FOR MNIST\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "# DEFINE THE NETWORK\n",
    "#\n",
    "#\n",
    "\n",
    "# helper function to define tf variables for initialized layer weights\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# helper function to define tf variables for initialized layer bias\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# helper function to define convolution layers\n",
    "# noinspection PyShadowingNames\n",
    "def conv2d(x, W):\n",
    "    # same convolution stride 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# helper function to define convolution layers\n",
    "# noinspection PyShadowingNames\n",
    "def trans_conv2d(x, W, outputShape):\n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape=outputShape,\n",
    "                                  strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# helper function to define pooling layers\n",
    "# noinspection PyShadowingNames\n",
    "def max_pool_2x2(x):\n",
    "    # max pooling with 2x2 blocks\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "#\n",
    "# now realy start defining the convolutional network\n",
    "#\n",
    "\n",
    "# specify input values\n",
    "# (given later as placeholder)\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "# reshape network input (placeholder) to 4D tensor\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "\n",
    "# 1st layer (conv-relu-maxpool)\n",
    "# 3x3 filter with 1 input channels and 8 output channels\n",
    "# bias for each output channel\n",
    "# reduces size to 14x14\n",
    "W_conv1 = weight_variable([3, 3, 1, 8])\n",
    "b_conv1 = bias_variable([8])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\n",
    "# 2nd layer (conv-relu-maxpool)\n",
    "# 3x3 filter with 8 input channels and 4 output channels\n",
    "# reduces size to 7x7\n",
    "W_conv2 = weight_variable([3, 3, 8, 4])\n",
    "b_conv2 = bias_variable([4])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "# 3rd layer (conv-relu)\n",
    "# 3x3 filter with 4 input channels and 2 output channels\n",
    "# reduces size to 7x7\n",
    "W_conv3 = weight_variable([3, 3, 4, 2])\n",
    "b_conv3 = bias_variable([2])\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "\n",
    "\n",
    "# 4th layer (transconv-relu)\n",
    "# 2x2 transpose-filter with 2 input channels and 4 output channels\n",
    "# increases size to 14x14\n",
    "W_tconv4 = weight_variable([2, 2, 4, 2])  # [x, y, outshape, inshape]\n",
    "b_tconv4 = bias_variable([4])\n",
    "h_tconv4 = tf.nn.relu(trans_conv2d(h_conv3, W_tconv4, outputShape=[64, 14, 14, 4]) + b_tconv4)\n",
    "\n",
    "\n",
    "# 5th layer (conv-relu)\n",
    "# 3x3 filter with 4 input channels and 4 output channels\n",
    "W_conv5 = weight_variable([3, 3, 4, 4])\n",
    "b_conv5 = bias_variable([4])\n",
    "h_conv5 = tf.nn.relu(conv2d(h_tconv4, W_conv5) + b_conv5)\n",
    "\n",
    "\n",
    "# 6th layer (transconv-relu)\n",
    "# 2x2 transpose-filter with 4 input channels and 8 output channels\n",
    "# increases size to 28x28\n",
    "W_tconv6 = weight_variable([2, 2, 8, 4])  # [x, y, outshape, inshape]\n",
    "b_tconv6 = bias_variable([8])\n",
    "h_tconv6 = tf.nn.relu(trans_conv2d(h_conv5, W_tconv6, outputShape=[64, 28, 28, 8]) + b_tconv6)\n",
    "\n",
    "\n",
    "# 7th layer (conv-relu)\n",
    "# 3x3 filter with 8 input channels and 8 output channels\n",
    "W_conv7 = weight_variable([3, 3, 8, 8])\n",
    "b_conv7 = bias_variable([8])\n",
    "h_conv7 = tf.nn.relu(conv2d(h_tconv6, W_conv7) + b_conv7)\n",
    "\n",
    "\n",
    "# 8th layer (conv-relu)\n",
    "# 1x1 filter with 8 input channels and 1 output channels\n",
    "W_conv8 = weight_variable([1, 1, 8, 1])\n",
    "b_conv8 = bias_variable([1])\n",
    "h_conv8 = tf.nn.relu(conv2d(h_conv7, W_conv8) + b_conv8)\n",
    "\n",
    "\n",
    "# squared loss\n",
    "mean_squared_loss = tf.reduce_mean(tf.squared_difference(h_conv8, x_image))\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "# TRAINING\n",
    "#\n",
    "#\n",
    "\n",
    "# define training step with ADAM\n",
    "trainsteps = [(tf.train.AdamOptimizer(0.01).minimize(mean_squared_loss), 0.01),\n",
    "              (tf.train.AdamOptimizer(0.01).minimize(mean_squared_loss), 0.01),\n",
    "              (tf.train.AdamOptimizer(0.01).minimize(mean_squared_loss), 0.01)]\n",
    "\n",
    "# load the training data set MNIST\n",
    "mnist = input_data.read_data_sets('MNIST_data')  # optional one_hot=True (not necessary here)\n",
    "\n",
    "# run training:\n",
    "# logging train and validation loss every 100 iterations\n",
    "with tf.Session() as sess:\n",
    "    for trainstep, learningRate in trainsteps:\n",
    "        print(\"start training autoencoder with learning rate\", learningRate)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        #\n",
    "        # train autoencoder with certain learning rate\n",
    "        #\n",
    "        for i in range(15000):\n",
    "            batch = mnist.train.next_batch(64)\n",
    "            if i % 100 == 0:\n",
    "                #\n",
    "                # calculate training and validation loss here\n",
    "                #\n",
    "                trainloss = mean_squared_loss.eval(feed_dict={\n",
    "                    x: batch[0]})\n",
    "                print('step {}, train loss (one batch a 64) {}'.format(i, trainloss))\n",
    "                validationloss = mean_squared_loss.eval(feed_dict={\n",
    "                    x: mnist.test.next_batch(64)[0]})\n",
    "                print('step {}, validation loss (one val.batch a 64) {}'.format(i, validationloss))\n",
    "            # train step on same batch already used for logging. train step should happen after logging in this case.\n",
    "            trainstep.run(feed_dict={x: batch[0]})\n",
    "        print(\"finished training autoencoder\")\n",
    "\n",
    "        #\n",
    "        # print some examples\n",
    "        #\n",
    "        example_train_immages = mnist.train.next_batch(64)[0]\n",
    "        example_train_processed = h_conv8.eval(feed_dict={x: example_train_immages})\n",
    "        example_test_immages = mnist.test.next_batch(64)[0]\n",
    "        example_test_processed = h_conv8.eval(feed_dict={x: example_test_immages})\n",
    "        print(\"EXAMPLE RESULTS\")\n",
    "\n",
    "        print(\"EXAMPLE TRAIN IMMAGES\")\n",
    "        for imnr in range(len(example_train_immages)):\n",
    "            print(\"IMNR\", imnr)\n",
    "            for pixnr in range(len(example_train_immages[0])):\n",
    "                print(example_train_immages[imnr][pixnr])\n",
    "        print(\"EXAMPLE TRAIN PROCESSED\")\n",
    "        for imnr in range(len(example_train_processed)):\n",
    "            print(\"IMNR\", imnr)\n",
    "            for pixnr_X in range(len(example_train_processed[0])):\n",
    "                for pixnr_Y in range(len(example_train_processed[0][0])):\n",
    "                    print(example_train_processed[imnr][pixnr_X][pixnr_Y])\n",
    "        print(\"EXAMPLE TEST IMMAGES\")\n",
    "        for imnr in range(len(example_test_immages)):\n",
    "            print(\"IMNR\", imnr)\n",
    "            for pixnr in range(len(example_test_immages[0])):\n",
    "                print(example_test_immages[imnr][pixnr])\n",
    "        print(\"EXAMPLE TEST PROCESSED\")\n",
    "        for imnr in range(len(example_test_processed)):\n",
    "            print(\"IMNR\", imnr)\n",
    "            for pixnr_X in range(len(example_test_processed[0])):\n",
    "                for pixnr_Y in range(len(example_test_processed[0][0])):\n",
    "                    print(example_test_processed[imnr][pixnr_X][pixnr_Y])\n",
    "\n",
    "\n",
    "print(\"program finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First exercise: Classifying MNIST with MLPs\n",
    "In this exercise you will implement a Neural Network (or MLP) and classify the MNIST digits with it.\n",
    "MNIST is a \"well hung\" dataset that has been used a lot over the years to benchmark different classification algorithms. \n",
    "To learn more about it have a look here: http://yann.lecun.com/exdb/mnist/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "We first define a function for downloading and loading MNIST.\n",
    "**WARNING**: Executing it will obviously use up some space on your machine ;). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
