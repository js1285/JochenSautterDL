{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist_tutorial/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist_tutorial/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist_tutorial/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist_tutorial/data/t10k-labels-idx1-ubyte.gz\n",
      "Necessary data files were not found. Run this command from inside the repo provided at https://github.com/dandelionmane/tf-dev-summit-tensorboard-tutorial.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "LOGDIR = \"/tmp/mnist_tutorial/\"\n",
    "LABELS = os.path.join(os.getcwd(), \"labels_1024.tsv\")\n",
    "SPRITES = os.path.join(os.getcwd(), \"sprite_1024.png\")\n",
    "### MNIST EMBEDDINGS ###\n",
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=LOGDIR + \"data\", one_hot=True)\n",
    "### Get a sprite and labels file for the embedding projector ###\n",
    "\n",
    "if not (os.path.isfile(LABELS) and os.path.isfile(SPRITES)):\n",
    "  print(\"Necessary data files were not found. Run this command from inside the \"\n",
    "    \"repo provided at \"\n",
    "    \"https://github.com/dandelionmane/tf-dev-summit-tensorboard-tutorial.\")\n",
    "  exit(1)\n",
    "\n",
    "\n",
    "# shutil.copyfile(LABELS, os.path.join(LOGDIR, LABELS))\n",
    "# shutil.copyfile(SPRITES, os.path.join(LOGDIR, SPRITES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "    conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    act = tf.nn.relu(conv + b)\n",
    "    tf.summary.histogram(\"weights\", w)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", act)\n",
    "    return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "  with tf.name_scope(name):     # name_scope go cause all related ops to have the same naming structure \n",
    "    w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "    act = tf.matmul(input, w) + b\n",
    "    tf.summary.histogram(\"weights\", w)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", act)\n",
    "    return act\n",
    "\n",
    "\n",
    "def mnist_model(learning_rate, use_two_fc, use_two_conv, hparam):\n",
    "  tf.reset_default_graph()\n",
    "  sess = tf.Session()\n",
    "\n",
    "  # Setup placeholders, and reshape the data\n",
    "  x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "  x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "  tf.summary.image('input', x_image, 3)\n",
    "  y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "\n",
    "  if use_two_conv:\n",
    "    conv1 = conv_layer(x_image, 1, 32, \"conv1\")\n",
    "    conv_out = conv_layer(conv1, 32, 64, \"conv2\")\n",
    "  else:\n",
    "    conv1 = conv_layer(x_image, 1, 64, \"conv\")\n",
    "    conv_out = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "  flattened = tf.reshape(conv_out, [-1, 7 * 7 * 64])\n",
    "\n",
    "\n",
    "  if use_two_fc:   # \n",
    "    fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, \"fc1\")\n",
    "    relu = tf.nn.relu(fc1)\n",
    "    embedding_input = relu\n",
    "    tf.summary.histogram(\"fc1/relu\", relu)\n",
    "    embedding_size = 1024\n",
    "    logits = fc_layer(fc1, 1024, 10, \"fc2\")\n",
    "  else:\n",
    "    embedding_input = flattened\n",
    "    embedding_size = 7*7*64\n",
    "    logits = fc_layer(flattened, 7*7*64, 10, \"fc\")\n",
    "\n",
    "  with tf.name_scope(\"xent\"):\n",
    "    xent = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=y), name=\"xent\")\n",
    "    tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "  with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "\n",
    "  with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "  summ = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "  embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"test_embedding\")\n",
    "  assignment = embedding.assign(embedding_input)\n",
    "  saver = tf.train.Saver()\n",
    "\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  # a python class that writes protocol output buffers on the disk --> pass it the directory\n",
    "  # scalar summaries: just numbers, image summaries: images, \n",
    "  # histogram summaries, shape of distributions of variables, like weights\n",
    "  # summary op gives us the protocol buffers, filewriter writes them to disk  \n",
    "  writer = tf.summary.FileWriter(LOGDIR + hparam)\n",
    "  writer.add_graph(sess.graph)    # add our sessions graph to that writer\n",
    "\n",
    "  config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "  embedding_config = config.embeddings.add()\n",
    "  embedding_config.tensor_name = embedding.name\n",
    "  embedding_config.sprite.image_path = SPRITES\n",
    "  embedding_config.metadata_path = LABELS\n",
    "  # Specify the width and height of a single thumbnail.\n",
    "  embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "  tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
    "\n",
    "  for i in range(201):   # my original was 2001\n",
    "    batch = mnist.train.next_batch(10)   # my original was 100\n",
    "    if i % 5 == 0:\n",
    "      [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: batch[0], y: batch[1]})\n",
    "      writer.add_summary(s, i)\n",
    "      print(\"loop {}\".format(i))    # mystuff\n",
    "    if i % 50 == 0:                # my original was 500\n",
    "      sess.run(assignment, feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]})\n",
    "      saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "def make_hparam_string(learning_rate, use_two_fc, use_two_conv):\n",
    "  conv_param = \"conv=2\" if use_two_conv else \"conv=1\"\n",
    "  fc_param = \"fc=2\" if use_two_fc else \"fc=1\"\n",
    "  return \"lr_%.0E,%s,%s\" % (learning_rate, conv_param, fc_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for lr_1E-03,conv=1,fc=2\n",
      "loop 0\n",
      "loop 5\n",
      "loop 10\n",
      "loop 15\n",
      "loop 20\n",
      "loop 25\n",
      "loop 30\n",
      "loop 35\n",
      "loop 40\n",
      "loop 45\n",
      "loop 50\n",
      "loop 55\n",
      "loop 60\n",
      "loop 65\n",
      "loop 70\n",
      "loop 75\n",
      "loop 80\n",
      "loop 85\n",
      "loop 90\n",
      "loop 95\n",
      "loop 100\n",
      "loop 105\n",
      "loop 110\n",
      "loop 115\n",
      "loop 120\n",
      "loop 125\n",
      "loop 130\n",
      "loop 135\n",
      "loop 140\n",
      "loop 145\n",
      "loop 150\n",
      "loop 155\n",
      "loop 160\n",
      "loop 165\n",
      "loop 170\n",
      "loop 175\n",
      "loop 180\n",
      "loop 185\n",
      "loop 190\n",
      "loop 195\n",
      "loop 200\n",
      "Starting run for lr_1E-03,conv=2,fc=2\n",
      "loop 0\n",
      "loop 5\n",
      "loop 10\n",
      "loop 15\n",
      "loop 20\n",
      "loop 25\n",
      "loop 30\n",
      "loop 35\n",
      "loop 40\n",
      "loop 45\n",
      "loop 50\n",
      "loop 55\n",
      "loop 60\n",
      "loop 65\n",
      "loop 70\n",
      "loop 75\n",
      "loop 80\n",
      "loop 85\n",
      "loop 90\n",
      "loop 95\n",
      "loop 100\n",
      "loop 105\n",
      "loop 110\n",
      "loop 115\n",
      "loop 120\n",
      "loop 125\n",
      "loop 130\n",
      "loop 135\n",
      "loop 140\n",
      "loop 145\n",
      "loop 150\n",
      "loop 155\n",
      "loop 160\n",
      "loop 165\n",
      "loop 170\n",
      "loop 175\n",
      "loop 180\n",
      "loop 185\n",
      "loop 190\n",
      "loop 195\n",
      "loop 200\n",
      "Starting run for lr_1E-04,conv=1,fc=2\n",
      "loop 0\n",
      "loop 5\n",
      "loop 10\n",
      "loop 15\n",
      "loop 20\n",
      "loop 25\n",
      "loop 30\n",
      "loop 35\n",
      "loop 40\n",
      "loop 45\n",
      "loop 50\n",
      "loop 55\n",
      "loop 60\n",
      "loop 65\n",
      "loop 70\n",
      "loop 75\n",
      "loop 80\n",
      "loop 85\n",
      "loop 90\n",
      "loop 95\n",
      "loop 100\n",
      "loop 105\n",
      "loop 110\n",
      "loop 115\n",
      "loop 120\n",
      "loop 125\n",
      "loop 130\n",
      "loop 135\n",
      "loop 140\n",
      "loop 145\n",
      "loop 150\n",
      "loop 155\n",
      "loop 160\n",
      "loop 165\n",
      "loop 170\n",
      "loop 175\n",
      "loop 180\n",
      "loop 185\n",
      "loop 190\n",
      "loop 195\n",
      "loop 200\n",
      "Starting run for lr_1E-04,conv=2,fc=2\n",
      "loop 0\n",
      "loop 5\n",
      "loop 10\n",
      "loop 15\n",
      "loop 20\n",
      "loop 25\n",
      "loop 30\n",
      "loop 35\n",
      "loop 40\n",
      "loop 45\n",
      "loop 50\n",
      "loop 55\n",
      "loop 60\n",
      "loop 65\n",
      "loop 70\n",
      "loop 75\n",
      "loop 80\n",
      "loop 85\n",
      "loop 90\n",
      "loop 95\n",
      "loop 100\n",
      "loop 105\n",
      "loop 110\n",
      "loop 115\n",
      "loop 120\n",
      "loop 125\n",
      "loop 130\n",
      "loop 135\n",
      "loop 140\n",
      "loop 145\n",
      "loop 150\n",
      "loop 155\n",
      "loop 160\n",
      "loop 165\n",
      "loop 170\n",
      "loop 175\n",
      "loop 180\n",
      "loop 185\n",
      "loop 190\n",
      "loop 195\n",
      "loop 200\n",
      "Done training!\n",
      "Run `tensorboard --logdir=/tmp/mnist_tutorial/` to see the results.\n",
      "Running on mac? If you want to get rid of the dialogue asking to give network permissions to TensorBoard, you can provide this flag: --host=localhost\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  # You can try adding some more learning rates\n",
    "  for learning_rate in [1E-3, 1E-4]:\n",
    "\n",
    "    # Include \"False\" as a value to try different model architectures\n",
    "    for use_two_fc in [True]:\n",
    "      for use_two_conv in [False, True]:\n",
    "        # Construct a hyperparameter string for each one (example: \"lr_1E-3,fc=2,conv=2\")\n",
    "        hparam = make_hparam_string(learning_rate, use_two_fc, use_two_conv)\n",
    "        print('Starting run for %s' % hparam)\n",
    "\n",
    "        # Actually run with the new settings\n",
    "        mnist_model(learning_rate, use_two_fc, use_two_conv, hparam)\n",
    "  print('Done training!')\n",
    "  print('Run `tensorboard --logdir=%s` to see the results.' % LOGDIR)\n",
    "  print('Running on mac? If you want to get rid of the dialogue asking to give '\n",
    "        'network permissions to TensorBoard, you can provide this flag: '\n",
    "        '--host=localhost')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()\n",
    "\n",
    "# tensorboard --logdir=/tmp/mnist_tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
