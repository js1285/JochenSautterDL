{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "import keras_model as km\n",
    "import keras_tools as tools\n",
    "import utilities as ut\n",
    "import numpy as np\n",
    "import Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old directory removed data/model_train\n",
      "old directory removed data/model_valid\n",
      "copy 34 images for whale # 1, called w_1287fbc\n",
      "copy 27 images for whale # 2, called w_98baff9\n",
      "copy 26 images for whale # 3, called w_7554f44\n",
      "copy 23 images for whale # 4, called w_1eafe46\n",
      "copy 22 images for whale # 5, called w_693c9ee\n",
      "copy 22 images for whale # 6, called w_ab4cae2\n",
      "copy 22 images for whale # 7, called w_fd1cb9d\n",
      "copy 21 images for whale # 8, called w_43be268\n",
      "copy 21 images for whale # 9, called w_73d5489\n",
      "copy 21 images for whale # 10, called w_987a36f\n",
      "239  images of  10  whales copied in total\n",
      "Target Directory train:  data/model_train  validation:  data/model_valid\n",
      "156  images copied as training data\n",
      "83  images copied as validation data\n",
      "write csv file with training data: data/model_train.csv\n",
      "write csv file with validation data: data/model_valid.csv\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "num_train_imgs, num_valid_imgs = ut.create_small_case(\n",
    "    sel_whales=np.arange(1, num_classes+1),\n",
    "    train_dir=\"data/model_train\",        # copy data into this directory and train there\n",
    "    train_csv=\"data/model_train.csv\",    # copy data into this directory and train there\n",
    "    valid_dir=\"data/model_valid\",\n",
    "    valid_csv=\"data/model_valid.csv\",\n",
    "    train_valid=0.8,\n",
    "    sub_dirs=True,\n",
    "    bag_no=4)    # count bag_no from 1,2,3,...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config_dict = {'base_model': 'MobileNet', \n",
    "               'num_dense_layers': 3,\n",
    "               'num_dense_units_0': 1024,\n",
    "               'num_dense_units_1': 1024,\n",
    "               'num_dense_units_2': 1024,\n",
    "               'activation': 'relu',\n",
    "               'dropout': True,\n",
    "               'dropout_0': 1.0,\n",
    "               'dropout_1': 0.5,\n",
    "               'dropout_2': 0.5,\n",
    "               'optimizer': \"RMSProp\",\n",
    "               'learning_rate': 0.001,    \n",
    "               'cnn_learning_rate': 0.0001,               \n",
    "               'cnn_unlock_epoch': 20,\n",
    "               'unfreeze_percentage': 0.2,             \n",
    "               'batch_size': 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model InceptionV3\n",
      "old directory removed data/model_train\n",
      "old directory removed data/model_valid\n",
      "copy 34 images for whale # 1, called w_1287fbc\n",
      "copy 27 images for whale # 2, called w_98baff9\n",
      "copy 26 images for whale # 3, called w_7554f44\n",
      "copy 23 images for whale # 4, called w_1eafe46\n",
      "copy 22 images for whale # 5, called w_693c9ee\n",
      "copy 22 images for whale # 6, called w_ab4cae2\n",
      "copy 22 images for whale # 7, called w_fd1cb9d\n",
      "copy 21 images for whale # 8, called w_43be268\n",
      "copy 21 images for whale # 9, called w_73d5489\n",
      "copy 21 images for whale # 10, called w_987a36f\n",
      "copy 20 images for whale # 11, called w_f19faeb\n",
      "copy 19 images for whale # 12, called w_95874a5\n",
      "copy 19 images for whale # 13, called w_9b401eb\n",
      "copy 18 images for whale # 14, called w_b7d5069\n",
      "copy 18 images for whale # 15, called w_c0d494d\n",
      "copy 17 images for whale # 16, called w_0e737d0\n",
      "copy 17 images for whale # 17, called w_18eee6e\n",
      "copy 17 images for whale # 18, called w_dbda0d6\n",
      "copy 17 images for whale # 19, called w_eb0a6ed\n",
      "copy 16 images for whale # 20, called w_17ee910\n",
      "417  images of  20  whales copied in total\n",
      "Target Directory train:  data/model_train  validation:  data/model_valid\n",
      "323  images copied as training data\n",
      "94  images copied as validation data\n",
      "write csv file with training data: data/model_train.csv\n",
      "write csv file with validation data: data/model_valid.csv\n",
      "Found 323 images belonging to 20 classes.\n",
      "Found 94 images belonging to 20 classes.\n",
      "Epoch 1/20\n",
      " - 8s - loss: 5.0614 - acc: 0.0724 - val_loss: 3.0455 - val_acc: 0.0696\n",
      "Epoch 2/20\n",
      " - 6s - loss: 2.9959 - acc: 0.0656 - val_loss: 2.9870 - val_acc: 0.0962\n",
      "Epoch 3/20\n",
      " - 6s - loss: 2.9211 - acc: 0.1196 - val_loss: 2.9363 - val_acc: 0.0769\n",
      "Epoch 4/20\n",
      " - 6s - loss: 2.7685 - acc: 0.1569 - val_loss: 2.8851 - val_acc: 0.0823\n",
      "Epoch 5/20\n",
      " - 5s - loss: 2.6840 - acc: 0.1503 - val_loss: 2.8897 - val_acc: 0.0705\n",
      "Epoch 6/20\n",
      " - 6s - loss: 2.6115 - acc: 0.1812 - val_loss: 2.7537 - val_acc: 0.1090\n",
      "Epoch 7/20\n",
      " - 5s - loss: 2.4264 - acc: 0.2067 - val_loss: 2.6853 - val_acc: 0.1899\n",
      "Epoch 8/20\n",
      " - 5s - loss: 2.6440 - acc: 0.1412 - val_loss: 2.6434 - val_acc: 0.1667\n",
      "Epoch 9/20\n",
      " - 5s - loss: 2.3694 - acc: 0.2411 - val_loss: 2.8521 - val_acc: 0.1282\n",
      "Epoch 10/20\n",
      " - 5s - loss: 2.2776 - acc: 0.2630 - val_loss: 3.2138 - val_acc: 0.1139\n",
      "Epoch 11/20\n",
      " - 5s - loss: 2.3836 - acc: 0.2536 - val_loss: 2.4596 - val_acc: 0.1859\n",
      "Epoch 12/20\n",
      " - 5s - loss: 2.1098 - acc: 0.2719 - val_loss: 2.7272 - val_acc: 0.1474\n",
      "Epoch 13/20\n",
      " - 5s - loss: 2.3708 - acc: 0.2348 - val_loss: 2.5669 - val_acc: 0.1772\n",
      "Epoch 14/20\n",
      " - 5s - loss: 2.3646 - acc: 0.2536 - val_loss: 2.4670 - val_acc: 0.2372\n",
      "Epoch 15/20\n",
      " - 5s - loss: 2.1526 - acc: 0.2630 - val_loss: 2.6095 - val_acc: 0.1795\n",
      "Epoch 16/20\n",
      " - 5s - loss: 2.2237 - acc: 0.2474 - val_loss: 2.7224 - val_acc: 0.1582\n",
      "Epoch 17/20\n",
      " - 5s - loss: 2.1527 - acc: 0.2912 - val_loss: 2.4986 - val_acc: 0.2051\n",
      "Epoch 18/20\n",
      " - 5s - loss: 2.1376 - acc: 0.2693 - val_loss: 3.3673 - val_acc: 0.1218\n",
      "Epoch 19/20\n",
      " - 5s - loss: 2.1182 - acc: 0.2479 - val_loss: 2.7460 - val_acc: 0.1772\n",
      "Epoch 20/20\n",
      " - 5s - loss: 2.1368 - acc: 0.2781 - val_loss: 3.2376 - val_acc: 0.1218\n",
      "\n",
      " ****** InceptionV3 unfrozen 2 top blocks, cut_off after layer 248 ******\n",
      "Epoch 1/20\n",
      " - 8s - loss: 2.0394 - acc: 0.3264 - val_loss: 2.7046 - val_acc: 0.1772\n",
      "Epoch 2/20\n",
      " - 6s - loss: 1.9281 - acc: 0.3225 - val_loss: 2.4594 - val_acc: 0.1474\n",
      "Epoch 3/20\n",
      " - 6s - loss: 1.7865 - acc: 0.3980 - val_loss: 2.4105 - val_acc: 0.1923\n",
      "Epoch 4/20\n",
      " - 6s - loss: 1.9009 - acc: 0.3417 - val_loss: 2.3797 - val_acc: 0.2215\n",
      "Epoch 5/20\n",
      " - 6s - loss: 1.9214 - acc: 0.3323 - val_loss: 2.4135 - val_acc: 0.2564\n",
      "Epoch 6/20\n",
      " - 6s - loss: 1.7954 - acc: 0.4071 - val_loss: 2.3420 - val_acc: 0.2500\n",
      "Epoch 7/20\n",
      " - 6s - loss: 1.5458 - acc: 0.4450 - val_loss: 2.3699 - val_acc: 0.2468\n",
      "Epoch 8/20\n",
      " - 6s - loss: 1.6745 - acc: 0.3824 - val_loss: 2.3061 - val_acc: 0.2436\n",
      "Epoch 9/20\n",
      " - 6s - loss: 1.5952 - acc: 0.4406 - val_loss: 2.1754 - val_acc: 0.2885\n",
      "Epoch 10/20\n",
      " - 5s - loss: 1.6436 - acc: 0.4372 - val_loss: 2.1530 - val_acc: 0.2911\n",
      "Epoch 11/20\n",
      " - 5s - loss: 1.6862 - acc: 0.3914 - val_loss: 2.2409 - val_acc: 0.2564\n",
      "Epoch 12/20\n",
      " - 5s - loss: 1.5954 - acc: 0.4290 - val_loss: 2.2471 - val_acc: 0.2756\n",
      "Epoch 13/20\n",
      " - 5s - loss: 1.5788 - acc: 0.4109 - val_loss: 2.1915 - val_acc: 0.2785\n",
      "Epoch 14/20\n",
      " - 5s - loss: 1.6408 - acc: 0.4062 - val_loss: 2.3762 - val_acc: 0.1987\n",
      "Epoch 15/20\n",
      " - 5s - loss: 1.5903 - acc: 0.4196 - val_loss: 2.2904 - val_acc: 0.2244\n",
      "Epoch 16/20\n",
      " - 5s - loss: 1.4911 - acc: 0.4321 - val_loss: 2.2724 - val_acc: 0.2278\n",
      "Epoch 17/20\n",
      " - 5s - loss: 1.5858 - acc: 0.4575 - val_loss: 2.3680 - val_acc: 0.2436\n",
      "Epoch 18/20\n",
      " - 5s - loss: 1.5720 - acc: 0.4415 - val_loss: 2.1932 - val_acc: 0.2821\n",
      "Epoch 19/20\n",
      " - 5s - loss: 1.5762 - acc: 0.4039 - val_loss: 2.1709 - val_acc: 0.3671\n",
      "Epoch 20/20\n",
      " - 5s - loss: 1.4063 - acc: 0.4701 - val_loss: 2.0919 - val_acc: 0.3718\n",
      "model saved:  model/180214_MobileNet_4250cl_40ep\n"
     ]
    }
   ],
   "source": [
    "# step 1: create baseline 20cl+20_0.2\n",
    "num_classes = 20    # for submission take 2031 classes: non unique whales. (otherwise validation with training data)\n",
    "config_dict=base_config_dict\n",
    "model = km._create_pretrained_model(config_dict, num_classes = num_classes)\n",
    "_, _, _, model = km.train(config_dict, epochs=20, model=model, num_classes=num_classes,\n",
    "                # save_data_path=\"plots\",\n",
    "                train_dir=\"data/model_train\",        # copy data into this directory and train there\n",
    "                train_csv=\"data/model_train.csv\",    # copy data into this directory and train there\n",
    "                valid_dir=\"data/model_valid\",\n",
    "                valid_csv=\"data/model_valid.csv\",\n",
    "                save_model_path=\"model/180411_MobileNet_20cl+20_0.2\",\n",
    "                train_valid_split=.8,\n",
    "                augmented = 'keras', \n",
    "                earlystop = False,\n",
    "                create_case = True,\n",
    "                unfreezings = [(20,0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: test earlystop after baseline 20 classes\n",
    "num_classes = 20    # for submission take 2031 classes: non unique whales. (otherwise validation with training data)\n",
    "config_dict=base_config_dict\n",
    "\n",
    "model = km._create_pretrained_model(config_dict, num_classes = num_classes)\n",
    "_, _, _, model = km.train(config_dict, epochs=20, model=model, num_classes=num_classes,\n",
    "                # save_data_path=\"plots\",\n",
    "                train_dir=\"data/model_train\",        # copy data into this directory and train there\n",
    "                train_csv=\"data/model_train.csv\",    # copy data into this directory and train there\n",
    "                valid_dir=\"data/model_valid\",\n",
    "                valid_csv=\"data/model_valid.csv\",\n",
    "                save_model_path=\"model/180411_MobileNet_20cl+ES_0.2\",\n",
    "                train_valid_split=.8,\n",
    "                augmented = 'keras', \n",
    "                earlystop = False,    # for first 20 epochs without unfreezing\n",
    "                create_case = True,\n",
    "                unfreezings = [(-1,0.2)])  # earlystop after unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: test unfreeze gradually after baseline 20 classes\n",
    "num_classes = 20    # for submission take 2031 classes: non unique whales. (otherwise validation with training data)\n",
    "config_dict=base_config_dict\n",
    "model = km._create_pretrained_model(config_dict, num_classes = num_classes)\n",
    "\n",
    "_, _, _, model = km.train(config_dict, epochs=20, model=model, num_classes=num_classes,\n",
    "                # save_data_path=\"plots\",\n",
    "                train_dir=\"data/model_train\",        # copy data into this directory and train there\n",
    "                train_csv=\"data/model_train.csv\",    # copy data into this directory and train there\n",
    "                valid_dir=\"data/model_valid\",\n",
    "                valid_csv=\"data/model_valid.csv\",\n",
    "                save_model_path=\"model/180411_MobileNet_20cl+(25,0.2),(25,0.4),(25,0.6),(25,0.8),(25,1.0)\",\n",
    "                train_valid_split=.8,\n",
    "                augmented = 'keras', \n",
    "                earlystop = False,\n",
    "                create_case = True,\n",
    "                unfreezings = [(25,0.2),(25,0.4),(25,0.6),(25,0.8),(-1,1.0)])  # earlystop after unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: test bagging implementation with baseline 20+20_0.2 classes\n",
    "num_classes = 20    # for submission take 2031 classes: non unique whales. (otherwise validation with training data)\n",
    "config_dict=base_config_dict\n",
    "model = km._create_pretrained_model(config_dict, num_classes = num_classes)\n",
    "_, _, _, models = km.train_bagging(config_dict, epochs=20, model=model, num_classes=num_classes,\n",
    "                # save_data_path=\"plots\",\n",
    "                train_dir=\"data/model_train\",        # copy data into this directory and train there\n",
    "                train_csv=\"data/model_train.csv\",    # copy data into this directory and train there\n",
    "                valid_dir=\"data/model_valid\",\n",
    "                valid_csv=\"data/model_valid.csv\",\n",
    "                save_model_path=\"model/180411_MobileNet_20cl+20_0.2_bag3\",\n",
    "                train_valid_split=.8,\n",
    "                augmented = 'keras',\n",
    "                bagging_no = 3,\n",
    "                earlystop = False,\n",
    "                create_case = True,\n",
    "                unfreezings = [(20,0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5: compare augmentor augmentation with baseline #2 (with Earlystop)\n",
    "num_classes = 20    # for submission take 2031 classes: non unique whales. (otherwise validation with training data)\n",
    "config_dict=base_config_dict\n",
    "\n",
    "model = km._create_pretrained_model(config_dict, num_classes = num_classes)\n",
    "_, _, _, model = km.train(config_dict, epochs=20, model=model, num_classes=num_classes,\n",
    "                # save_data_path=\"plots\",\n",
    "                train_dir=\"data/model_train\",        # copy data into this directory and train there\n",
    "                train_csv=\"data/model_train.csv\",    # copy data into this directory and train there\n",
    "                valid_dir=\"data/model_valid\",\n",
    "                valid_csv=\"data/model_valid.csv\",\n",
    "                save_model_path=\"model/180411_MobileNet_20cl+ES_0.2\",\n",
    "                train_valid_split=.8,\n",
    "                augmented = 'augmentor', # here with augmentor tool_box \n",
    "                earlystop = False,    \n",
    "                create_case = True,\n",
    "                unfreezings = [(-1,0.2)])  # earlystop after unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names, model_preds, true_labels, probs_list = \n",
    "    tools.compute_bagged_preds(models, num_classes, train_dir=\"data/model_train\", \n",
    "                               test_dir = \"data/my_bag_test\", test_csv = '')\n",
    "# tools.write_pred_to_csv(file_names,model_preds, path = \"data/test_submission_180411_MobileNet_20cl+20:0.2_bag3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create baseline 2031 based on experiences made before: \n",
    "# best practice for earlystop, augmentation, top preds, unfreezing\n",
    "# without bagging, without model_ensemble\n",
    "num_classes = 2031    # for submission take 2031 classes: non unique whales. (otherwise validation with training data)\n",
    "config_dict=base_config_dict\n",
    "\n",
    "model = km._create_pretrained_model(config_dict, num_classes = num_classes)\n",
    "_, _, _, model = km.train(config_dict, epochs=20, model=model, num_classes=num_classes,\n",
    "                # save_data_path=\"plots\",\n",
    "                train_dir=\"data/model_train_2031\",    # copy data into this directory and train there\n",
    "                train_csv=\"data/model_train_2031.csv\",    # copy data into this directory and train there\n",
    "                valid_dir=\"data/model_valid_2031\",\n",
    "                valid_csv=\"data/model_valid_2031.csv\",\n",
    "                save_model_path=\"model/180411_MobileNet_2031cl_20+20_0.2+ES_0.4\",\n",
    "                train_valid_split=.8,\n",
    "                earlystop = False,                          \n",
    "                create_case = True, \n",
    "                unfreezings = [(20,0.2),(-1,0.4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names, model_preds, true_labels, probs_list = \n",
    "    tools.compute_bagged_preds(models, num_classes, train_dir = \"data/model_train_2031\",\n",
    "                               test_dir = \"data/kaggle_test\", test_csv = '')\n",
    "tools.write_pred_to_csv(file_names,model_preds, \n",
    "                        path = \"data/submission_180411_MobileNet_2031cl_20+20_0.2+ES_0.4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2031 classes like baseline but with bagging\n",
    "num_classes = 2031    # for submission take 2031 classes: non unique whales. (otherwise validation with training data)\n",
    "config_dict=base_config_dict\n",
    "\n",
    "model = km._create_pretrained_model(config_dict, num_classes = num_classes)\n",
    "_, _, _, models = km.train_bagging(config_dict, epochs=20, model=model, num_classes=num_classes,\n",
    "                # save_data_path=\"plots\",\n",
    "                train_dir=\"data/model_train_2031\",    # copy data into this directory and train there\n",
    "                train_csv=\"data/model_train_2031.csv\",    # copy data into this directory and train there\n",
    "                valid_dir=\"data/model_valid_2031\",\n",
    "                valid_csv=\"data/model_valid_2031.csv\",\n",
    "                save_model_path=\"model/180411_MobileNet_2031cl_20+20_0.2+ES_0.4_bag3\",  \n",
    "                train_valid_split=.8,\n",
    "                earlystop = False,                          \n",
    "          tbd      create_case = True,\n",
    "                unfreezings = [(20,0.2),(-1,0.4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.pickle_to_file(models, \"model/180411_MobileNet_2031cl_20+20_0.2+ES_0.4_bag3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 2031 classes like baseline but with bagging to csv for kaggle evaluation\n",
    "file_names, model_preds, true_labels, probs_list = \n",
    "    tools.compute_bagged_preds(models, num_classes, train_dir=\"data/model_train_2031\", \n",
    "                               test_dir = \"data/kaggle_test\", test_csv = '')\n",
    "tools.write_pred_to_csv(file_names,model_preds, \n",
    "                        path = \"data/submission_180411_MobileNet_2031cl_20+20_0.2+ES_0.4_bag3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now best possible prediction with MobileNet\n",
    "num_classes = 2031    # for submission take 2031 classes: non unique whales. (otherwise validation with training data)\n",
    "config_dict=base_config_dict\n",
    "\n",
    "model = km._create_pretrained_model(config_dict, num_classes = num_classes)\n",
    "_, _, _, models = km.train_bagging(config_dict, epochs=20, model=model, num_classes=num_classes,\n",
    "                save_data_path=\"plots\",\n",
    "                train_dir=\"data/model_train_2031\",    # copy data into this directory and train there\n",
    "                train_csv=\"data/model_train_2031.csv\",    # copy data into this directory and train there\n",
    "                valid_dir=\"data/model_valid_2031\",\n",
    "                valid_csv=\"data/model_valid_2031.csv\",\n",
    "       tbd         save_model_path=\"model/180411_MobileNet_2031cl_20+20_0.2+ES_0.4_bag3\",  \n",
    "                train_valid_split=.8,\n",
    "                earlystop = False,                          \n",
    "       tbd         create_case = True,\n",
    "       tbd         unfreezings = [(20,0.2),(-1,0.4), TBD...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbd   ut.pickle_to_file(models, \"model/180411_MobileNet_2031cl_20+20_0.2+ES_0.4_bag3\")\n",
    "file_names, model_preds, _, probs_list = \n",
    "    tools.compute_bagged_preds(models, num_classes, train_dir=\"data/model_train_2031\",\n",
    "                               test_dir = \"data/kaggle_test\", test_csv = '')\n",
    "    \n",
    "ut.pickle_to_file(probs_list, \"model/probs_180411_MobileNet_2031cl_20+20_0.2+ES_0.4_bag3\")   tbd\n",
    "\n",
    "tools.write_pred_to_csv(file_names,model_preds, \n",
    "         tbd...               path = \"data/submission_180411_MobileNet_2031cl_20+20_0.2+ES_0.4_bag3.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2031 baseline with InceptionV3\n",
    "num_classes = 2031    # for submission take 2031 classes: non unique whales. (otherwise validation with training data)\n",
    "config_dict=base_config_dict\n",
    "config_dict['base_model'] = 'InceptionV3'\n",
    "model = km._create_pretrained_model(config_dict, num_classes = num_classes)\n",
    "_, _, _, model = km.train(config_dict, epochs=20, model=model, num_classes=num_classes,\n",
    "                save_data_path=\"plots\",\n",
    "                train_dir=\"data/model_train_2031\",    # copy data into this directory and train there\n",
    "                train_csv=\"data/model_train_2031.csv\",    # copy data into this directory and train there\n",
    "                valid_dir=\"data/model_valid_2031\",\n",
    "                valid_csv=\"data/model_valid_2031.csv\",\n",
    "                save_model_path=\"model/180411_InceptionV3_2031cl_20+20_0.2+ES_0.4\",\n",
    "                train_valid_split=.8,\n",
    "                earlystop = False,                          \n",
    "                create_case = True, \n",
    "                unfreezings = [(20,0.2),(-1,0.4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names, model_preds, true_labels, probs_list = \n",
    "    tools.compute_bagged_preds(models, num_classes, train_dir=\"data/model_train_2031\", \n",
    "                               test_dir = \"data/kaggle_test\", test_csv = '')\n",
    "tools.write_pred_to_csv(file_names,model_preds, \n",
    "                        path = \"data/submission_180411_InceptionV3_2031cl_20+20_0.2+ES_0.4.csv\")\n",
    "# check result with Kaggle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging bagged predictions with the three best base models \n",
    "probs_list = ut.pickle_from_file(\"model/probs_180411_MobileNet_2031cl_20+20_0.2+ES_0.4_bag3\")\n",
    "MobileNet_bagged_probs = np.mean(probs_list, axis=0)\n",
    "\n",
    "probs_list = ut.pickle_from_file(\"model/probs_180411_InceptionV3_2031cl_20+20_0.2+ES_0.4_bag3\")\n",
    "InceptionV3_bagged_probs = np.mean(probs_list, axis=0)\n",
    "\n",
    "probs_list = ut.pickle_from_file(\"model/probs_180411_Xception_2031cl_20+20_0.2+ES_0.4_bag3\")\n",
    "Xception_bagged_probs = np.mean(probs_list, axis=0)\n",
    "\n",
    "probs_avg = np.mean(MobileNet_bagged_probs,InceptionV3_bagged_probs,Xception_bagged_probs)\n",
    "\n",
    "model_preds = get_model_preds(\"data/model_train_2031\", probs_avg)\n",
    "\n",
    "test_flow = get_flow_from_dir(test_dir=\"data/kaggle_test\")\n",
    "file_names, _ = get_true_labels(test_flow, '')\n",
    "\n",
    "tools.write_pred_to_csv(file_names,model_preds, \n",
    "                     tbd...   path = \"data/submission_180411_3models_2031cl_20+20_0.2+ES_0.4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout preds: import good model from submission_2\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "with CustomObjectScope({'relu6': keras.applications.mobilenet.relu6,'DepthwiseConv2D': keras.applications.mobilenet.DepthwiseConv2D}):\n",
    "#     model = load_model('weights.hdf5')\n",
    "    model = load_model(\"model/180214_MobileNet_4250cl_20_20_35ep_unfr04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model MobileNet\n",
      "Found 15610 images belonging to 1 classes.\n",
      "976/976 [==============================] - 194s 199ms/step\n",
      "fn Whales/test/00029b3a.jpg\n",
      "fn Whales/test/0003c693.jpg\n",
      "fn Whales/test/000bc353.jpg\n"
     ]
    }
   ],
   "source": [
    "# then make prediction, store for further investigation\n",
    "file_names, model_preds, _, probs = \n",
    "    tools.compute_preds(model, num_classes, train_dir=\"data/model_train\", \n",
    "                        test_dir = \"data/kaggle_test\", test_csv = '')\n",
    "ut.pickle_to_file(probs, 'model/probs_180214_MobileNet_4250cl_20_20_35ep_unfr04')\n",
    "print(\"model_preds\", model_preds[:3])\n",
    "print(\"filenames\", len(file_names))\n",
    "print(\"first 10 filenames\", file_names[:10])\n",
    "print(\"gaga\". np.sort(probs)[:, ::-1][:10,:5]) # backwards, \n",
    "tools.write_pred_to_csv(file_names,model_preds, \n",
    "                        path = \"data/submission_180411_MobileNet_4250cl_20_20_35ep_unfr04.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new prediction with 'new_whale' only in second place if first whale prob exceeds threshold\n",
    "# first test new functions if reprocude same output file\n",
    "model_preds = get_model_preds(\"data/model_train_2031\", probs, threshold = 0.5)\n",
    "test_flow = get_flow_from_dir(test_dir=\"data/kaggle_test\")\n",
    "file_names, _ = get_true_labels(test_flow, '')\n",
    "\n",
    "tools.write_pred_to_csv_new(file_names,model_preds, \n",
    "                tbd...  path = \"data/test.csv\")\n",
    "# if funcs work, rewrite funcs definitively\n",
    "# then test with different thresholds, upload to kaggle, beginning with only few new_whales in second place\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
